{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "First we need an audio file to diarize."
      ],
      "metadata": {
        "id": "rJPK0lcCiB-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQU5EWQYiL8E",
        "outputId": "e1798226-704a-4d91-e548-eda3a14ddedc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install resemblyzer"
      ],
      "metadata": {
        "id": "CvisXbbkkp7Y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from resemblyzer import preprocess_wav, VoiceEncoder\n",
        "from pathlib import Path\n",
        "\n",
        "#give the file path to your audio file\n",
        "audio_file_path = '/content/drive/MyDrive/NLP Research/audio_data_donald_trump_real_4glfwiMXgwQ.mp3'\n",
        "wav_fpath = Path(audio_file_path)\n",
        "\n",
        "wav = preprocess_wav(wav_fpath)\n",
        "encoder = VoiceEncoder(\"cpu\")\n",
        "_, cont_embeds, wav_splits = encoder.embed_utterance(wav, return_partials=True, rate=16)\n",
        "print(cont_embeds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxSezkCWiXOT",
        "outputId": "1f12a9c0-50ef-4c9b-e58c-ee31fdbb3655"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.03 seconds.\n",
            "(545, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes the module might throw an error when you try to use an audio file having file extension different from wav, like mp3. In this case, you might need to convert your mp3 file to wav before using. You can use the below script (you will need to install pydub first)"
      ],
      "metadata": {
        "id": "T_Uol5mdlGCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf9VdduKlMYd",
        "outputId": "93366103-aeb8-4195-9d55-2366787b9a96"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "def mp3_to_wav(audio_file_path):\n",
        "    sound = AudioSegment.from_mp3(audio_file_path)\n",
        "    audio_file_path = audio_file_path.split('.')[0] + '.wav'\n",
        "    sound.export(audio_file_path, format=\"wav\")\n",
        "    return audio_file_path\n",
        "\n",
        "audio_file_path = mp3_to_wav(audio_file_path)\n",
        "print(audio_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KljcnF8xlG1j",
        "outputId": "c4a1e214-9008-4854-a46f-6174f5985111"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP Research/audio_data_donald_trump_real_4glfwiMXgwQ.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next step is the clustering of our d-vectors. For this, we will use an open source implementation of Spectral Clustering by Quan Wang, one of the original authors of the paper we are implementing, who has been generous enough to provide us with the code. "
      ],
      "metadata": {
        "id": "ToALve7HmFQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install spectralcluster"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGbEdvOqmGaF",
        "outputId": "db62463b-75a9-4e40-b187-46e2e4dd823b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spectralcluster\n",
            "  Downloading spectralcluster-0.2.16-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: spectralcluster\n",
            "Successfully installed spectralcluster-0.2.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spectralcluster import SpectralClusterer\n",
        "\n",
        "clusterer = SpectralClusterer(\n",
        "    min_clusters=2,\n",
        "    max_clusters=100\n",
        "    # p_percentile=0.90,\n",
        "    # gaussian_blur_sigma=1\n",
        ")\n",
        "\n",
        "labels = clusterer.predict(cont_embeds)"
      ],
      "metadata": {
        "id": "FvQF-gAQmMzv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating continuous segments"
      ],
      "metadata": {
        "id": "ldsH0uHJm5Vx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_labelling(labels,wav_splits):\n",
        "    from resemblyzer.audio import sampling_rate\n",
        "    times = [((s.start + s.stop) / 2) / sampling_rate for s in wav_splits]\n",
        "    labelling = []\n",
        "    start_time = 0\n",
        "\n",
        "    for i,time in enumerate(times):\n",
        "        if i>0 and labels[i]!=labels[i-1]:\n",
        "            temp = [str(labels[i-1]),start_time,time]\n",
        "            labelling.append(tuple(temp))\n",
        "            start_time = time\n",
        "        if i==len(times)-1:\n",
        "            temp = [str(labels[i]),start_time,time]\n",
        "            labelling.append(tuple(temp))\n",
        "\n",
        "    return labelling\n",
        "  \n",
        "labelling = create_labelling(labels,wav_splits)"
      ],
      "metadata": {
        "id": "kYW2FzqZm52w"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using our diarization labels"
      ],
      "metadata": {
        "id": "5a3agGICnPCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labelling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGMGAZp0nNF3",
        "outputId": "a80beba5-96fe-44c8-b3f3-751e2b111d21"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('0', 0, 2.6),\n",
              " ('1', 2.6, 4.64),\n",
              " ('0', 4.64, 4.76),\n",
              " ('1', 4.76, 4.88),\n",
              " ('0', 4.88, 6.26),\n",
              " ('1', 6.26, 8.12),\n",
              " ('0', 8.12, 8.18),\n",
              " ('1', 8.18, 8.24),\n",
              " ('0', 8.24, 10.58),\n",
              " ('1', 10.58, 11.84),\n",
              " ('0', 11.84, 12.26),\n",
              " ('1', 12.26, 13.28),\n",
              " ('0', 13.28, 13.4),\n",
              " ('1', 13.4, 13.64),\n",
              " ('0', 13.64, 13.76),\n",
              " ('1', 13.76, 21.32),\n",
              " ('0', 21.32, 21.74),\n",
              " ('1', 21.74, 21.8),\n",
              " ('0', 21.8, 21.92),\n",
              " ('1', 21.92, 22.1),\n",
              " ('0', 22.1, 25.52),\n",
              " ('1', 25.52, 26.6),\n",
              " ('0', 26.6, 30.08),\n",
              " ('1', 30.08, 30.68),\n",
              " ('0', 30.68, 31.1),\n",
              " ('1', 31.1, 31.52),\n",
              " ('0', 31.52, 33.44)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " You can now use these labels to create a text transcription of your audio call "
      ],
      "metadata": {
        "id": "K0HFsf06oHSa"
      }
    }
  ]
}